{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_s",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1q_-bAqdNqzFh1g1epew2fews7K1vJe1u",
      "authorship_tag": "ABX9TyNTzvu/FasNCdtVQX1+WXxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saumya0303/Deepspeech_Colab/blob/master/Deep_s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd3zYjPiMuOs",
        "colab_type": "code",
        "outputId": "d7e6fb63-9a97-4d02-d0ad-6fdf6b3556d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!pip3 install deepspeech"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepspeech\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/8b/82512dbb0a70a6b3ce11d3ee9165a8a2d5830f9e42f631b640685e5045dc/deepspeech-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (9.6MB)\n",
            "\u001b[K     |████████████████████████████████| 9.6MB 24.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from deepspeech) (1.18.2)\n",
            "Installing collected packages: deepspeech\n",
            "Successfully installed deepspeech-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfoNwaQUdzsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io.wavfile as wav\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "z, x = wav.read('/content/sample-000003.wav')\n",
        "x = x.astype('float32')\n",
        "data_tensor = tf.convert_to_tensor(x)\n",
        "\n",
        "a = tf.signal.stft(\n",
        "    data_tensor, 2048, 512, fft_length=None,\n",
        "    window_fn=tf.signal.hann_window, pad_end=False, name=None\n",
        ")\n",
        "\n",
        "#r = a.eval(session=tf.compat.v1.Session())\n",
        "\n",
        "p = tf.signal.inverse_stft(\n",
        "    a, 2048, 512, fft_length=None,\n",
        "    window_fn=tf.signal.hann_window, name=None\n",
        ")\n",
        "\n",
        "#signal_n = p.eval(session=tf.compat.v1.Session())\n",
        "wav.write('e1_modified.wav', z, p.numpy().astype('int16'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTD3LQCENxaI",
        "colab_type": "code",
        "outputId": "f8e4d086-192b-4d7e-e3ea-3be841e8093e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/deepspeech-0.6.1-models.tar.gz\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   620  100   620    0     0   2707      0 --:--:-- --:--:-- --:--:--  2707\n",
            "100 1172M  100 1172M    0     0  44.7M      0  0:00:26  0:00:26 --:--:-- 43.1M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN-pyoC9N1IB",
        "colab_type": "code",
        "outputId": "9ac6ee8d-7c48-4a97-db3f-187087f67ab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!tar xvf deepspeech-0.6.1-models.tar.gz"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "._deepspeech-0.6.1-models\n",
            "deepspeech-0.6.1-models/\n",
            "deepspeech-0.6.1-models/._lm.binary\n",
            "deepspeech-0.6.1-models/lm.binary\n",
            "deepspeech-0.6.1-models/._output_graph.pbmm\n",
            "deepspeech-0.6.1-models/output_graph.pbmm\n",
            "deepspeech-0.6.1-models/._output_graph.pb\n",
            "deepspeech-0.6.1-models/output_graph.pb\n",
            "deepspeech-0.6.1-models/._trie\n",
            "deepspeech-0.6.1-models/trie\n",
            "deepspeech-0.6.1-models/output_graph.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMgVEMO7OtTV",
        "colab_type": "code",
        "outputId": "51259416-a8a8-46d4-d45a-508ca1d4cea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --lm deepspeech-0.6.1-models/lm.binary --trie deepspeech-0.6.1-models/trie --audio /content/sample-000003.wav"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from file deepspeech-0.6.1-models/output_graph.pbmm\n",
            "TensorFlow: v1.14.0-21-ge77504a\n",
            "DeepSpeech: v0.6.1-0-g3df20fe\n",
            "Loaded model in 0.00914s.\n",
            "Loading language model from files deepspeech-0.6.1-models/lm.binary deepspeech-0.6.1-models/trie\n",
            "Loaded language model in 0.000203s.\n",
            "Running inference.\n",
            "down below in the darkness were hundreds of people sleeping in peace\n",
            "Inference took 5.368s for 7.680s audio file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjcr-kSEPNXV",
        "colab_type": "code",
        "outputId": "98a094c2-95b8-428f-83e0-50e74c69408b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --lm deepspeech-0.6.1-models/lm.binary --trie deepspeech-0.6.1-models/trie --audio /content/e1_modified.wav"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from file deepspeech-0.6.1-models/output_graph.pbmm\n",
            "TensorFlow: v1.14.0-21-ge77504a\n",
            "DeepSpeech: v0.6.1-0-g3df20fe\n",
            "Loaded model in 0.0116s.\n",
            "Loading language model from files deepspeech-0.6.1-models/lm.binary deepspeech-0.6.1-models/trie\n",
            "Loaded language model in 0.0002s.\n",
            "Running inference.\n",
            "down below in the darkness were hundreds of people sleeping in peace\n",
            "Inference took 5.288s for 7.680s audio file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkls0LwvPS0b",
        "colab_type": "code",
        "outputId": "c7a25cb3-6e7e-453a-fef1-d20a92a239a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --lm deepspeech-0.6.1-models/lm.binary --trie deepspeech-0.6.1-models/trie --audio /content/sample-000001.wav"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from file deepspeech-0.6.1-models/output_graph.pbmm\n",
            "TensorFlow: v1.14.0-21-ge77504a\n",
            "DeepSpeech: v0.6.1-0-g3df20fe\n",
            "2020-04-08 05:22:26.425761: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "Loaded model in 0.00818s.\n",
            "Loading language model from files deepspeech-0.6.1-models/lm.binary deepspeech-0.6.1-models/trie\n",
            "Loaded language model in 0.000184s.\n",
            "Running inference.\n",
            "of catcat have\n",
            "Inference took 1.335s for 1.920s audio file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_mR6mD8PYlk",
        "colab_type": "code",
        "outputId": "bf8b383c-d3de-4a65-9b01-8b3ac8accd95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --lm deepspeech-0.6.1-models/lm.binary --trie deepspeech-0.6.1-models/trie --audio /content/sample-000000.wav"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from file deepspeech-0.6.1-models/output_graph.pbmm\n",
            "TensorFlow: v1.14.0-21-ge77504a\n",
            "DeepSpeech: v0.6.1-0-g3df20fe\n",
            "2020-04-08 05:22:51.588842: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "Loaded model in 0.00798s.\n",
            "Loading language model from files deepspeech-0.6.1-models/lm.binary deepspeech-0.6.1-models/trie\n",
            "Loaded language model in 0.000177s.\n",
            "Running inference.\n",
            "without the data that the article useless\n",
            "Inference took 2.208s for 3.192s audio file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDHiPB7-cKOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}